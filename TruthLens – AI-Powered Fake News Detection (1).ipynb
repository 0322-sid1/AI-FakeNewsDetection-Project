{"cells":[{"cell_type":"markdown","metadata":{"id":"vQrbvStwyd6_"},"source":["# ***TruthLens – AI-Powered Fake News Detection***"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":30073,"status":"ok","timestamp":1756326300707,"user":{"displayName":"syeda subhana","userId":"05196957078571653966"},"user_tz":-300},"id":"OCBUvNoV06-D","outputId":"42bd3573-3c95-432c-c412-602e6f2d9cbd"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":[],"metadata":{"id":"O9HH9tYYHoh_","executionInfo":{"status":"ok","timestamp":1756326300718,"user_tz":-300,"elapsed":16,"user":{"displayName":"syeda subhana","userId":"05196957078571653966"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"s6jZ5yXY0n08"},"source":["**PROBLEM STATEMENT : **The problem is the unchecked spread of fake news online.\n","The solution is an ML/NLP-powered fake news detection system with explainability and a user-friendly deployment."]},{"cell_type":"markdown","metadata":{"id":"cwZVpNWjyibN"},"source":["Dataset Link: https://www.kaggle.com/datasets/vishakhdapat/fake-news-detection/data"]},{"cell_type":"markdown","metadata":{"id":"JFvTfWFL0zgA"},"source":["# **Data Collection & Preprocessing**"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":50075,"status":"ok","timestamp":1756326350801,"user":{"displayName":"syeda subhana","userId":"05196957078571653966"},"user_tz":-300},"id":"m3C0EGF70107","outputId":"5b7a3016-93d8-46ba-b463-8f8ae1f76bd6"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"]},{"output_type":"stream","name":"stdout","text":["Before cleaning:\n","                                                 Text label\n","0   Top Trump Surrogate BRUTALLY Stabs Him In The...  Fake\n","1  U.S. conservative leader optimistic of common ...  Real\n","2  Trump proposes U.S. tax overhaul, stirs concer...  Real\n","3   Court Forces Ohio To Allow Millions Of Illega...  Fake\n","4  Democrats say Trump agrees to work on immigrat...  Real\n","\n","After Encoding:\n","                                                 Text  label  \\\n","0   Top Trump Surrogate BRUTALLY Stabs Him In The...      0   \n","1  U.S. conservative leader optimistic of common ...      1   \n","2  Trump proposes U.S. tax overhaul, stirs concer...      1   \n","3   Court Forces Ohio To Allow Millions Of Illega...      0   \n","4  Democrats say Trump agrees to work on immigrat...      1   \n","\n","                                          clean_text  \n","0  top trump surrog brutal stab back pathet video...  \n","1  u conserv leader optimist common ground health...  \n","2  trump propos u tax overhaul stir concern defic...  \n","3  court forc ohio allow million illeg purg voter...  \n","4  democrat say trump agre work immigr bill wall ...  \n","\n","Train size: 7920, Test size: 1980\n","\n","Processed data saved as 'processed_fake_news.csv'\n"]}],"source":["import pandas as pd\n","import numpy as np\n","import re\n","from bs4 import BeautifulSoup\n","from nltk.corpus import stopwords\n","from nltk.stem import PorterStemmer\n","from sklearn.model_selection import train_test_split\n","import nltk\n","\n","nltk.download('stopwords')\n","\n","# 1. Load Dataset\n","# Update the file path to where your dataset is located in Google Drive\n","df = pd.read_csv(\"/content/drive/MyDrive/FakeNewsDetection_Project/fake_and_real_news.csv\")\n","print(\"Before cleaning:\\n\", df.head())\n","\n","# 2. Text Cleaning\n","stop_words = set(stopwords.words('english'))\n","stemmer = PorterStemmer()\n","\n","def clean_text(text):\n","    # Lowercase\n","    text = str(text).lower()\n","    # Remove HTML\n","    text = BeautifulSoup(text, \"html.parser\").get_text()\n","    # Remove punctuation & numbers\n","    text = re.sub(r'[^a-zA-Z]', ' ', text)\n","    # Tokenization & remove stopwords\n","    words = text.split()\n","    words = [w for w in words if w not in stop_words]\n","    # Stemming\n","    words = [stemmer.stem(w) for w in words]\n","    return \" \".join(words)\n","\n","df[\"clean_text\"] = df[\"Text\"].apply(clean_text)\n","\n","# 3. Label Encoding\n","df[\"label\"] = df[\"label\"].map({\"Fake\": 0, \"Real\": 1})\n","\n","print(\"\\nAfter Encoding:\\n\", df.head())\n","\n","# 4. Train-Test Split\n","X = df[\"clean_text\"]\n","y = df[\"label\"]\n","\n","from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train, y_test = train_test_split(\n","    X, y, test_size=0.2, random_state=42\n",")\n","\n","print(f\"\\nTrain size: {X_train.shape[0]}, Test size: {X_test.shape[0]}\")\n","\n","# 5. Save Processed Data\n","df[[\"clean_text\", \"label\"]].to_csv(\"processed_fake_news.csv\", index=False)\n","print(\"\\nProcessed data saved as 'processed_fake_news.csv'\")"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":120,"status":"ok","timestamp":1756326350924,"user":{"displayName":"syeda subhana","userId":"05196957078571653966"},"user_tz":-300},"id":"Y_2TeD5C5I_u","outputId":"d072a972-4f7e-4f61-ff1b-19f29e6569a5"},"outputs":[{"output_type":"stream","name":"stdout","text":["drive  processed_fake_news.csv\tsample_data\n"]}],"source":["!ls\n","\n"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"MrIZh85O5Yvp","executionInfo":{"status":"ok","timestamp":1756326351823,"user_tz":-300,"elapsed":891,"user":{"displayName":"syeda subhana","userId":"05196957078571653966"}}},"outputs":[],"source":["!cp processed_fake_news.csv /content/drive/MyDrive/FakeNewsDetection_Project/\n"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":0,"status":"ok","timestamp":1756326407041,"user":{"displayName":"syeda subhana","userId":"05196957078571653966"},"user_tz":-300},"id":"JxFtWXx5-HYZ","outputId":"b132906f-34af-4bf7-e127-c220d2a69a69"},"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","=== TF-IDF + Logistic Regression ===\n","Accuracy: 0.9949494949494949\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.99      0.99       973\n","           1       0.99      1.00      1.00      1007\n","\n","    accuracy                           0.99      1980\n","   macro avg       0.99      0.99      0.99      1980\n","weighted avg       0.99      0.99      0.99      1980\n","\n","\n","=== TF-IDF + Random Forest ===\n","Accuracy: 0.998989898989899\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00       973\n","           1       1.00      1.00      1.00      1007\n","\n","    accuracy                           1.00      1980\n","   macro avg       1.00      1.00      1.00      1980\n","weighted avg       1.00      1.00      1.00      1980\n","\n","\n","=== Dense Neural Network ===\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch 1/3\n","\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.7740 - loss: 0.5174 - val_accuracy: 0.9804 - val_loss: 0.0787\n","Epoch 2/3\n","\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9831 - loss: 0.0655 - val_accuracy: 0.9924 - val_loss: 0.0294\n","Epoch 3/3\n","\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9953 - loss: 0.0209 - val_accuracy: 0.9949 - val_loss: 0.0163\n","\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9968 - loss: 0.0142\n","Dense NN Accuracy: 0.9959595799446106\n","\n","=== LSTM ===\n","Epoch 1/3\n","\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 20ms/step - accuracy: 0.8256 - loss: 0.3938 - val_accuracy: 0.9880 - val_loss: 0.0480\n","Epoch 2/3\n","\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9891 - loss: 0.0485 - val_accuracy: 0.9949 - val_loss: 0.0213\n","Epoch 3/3\n","\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9875 - loss: 0.0468 - val_accuracy: 0.9874 - val_loss: 0.0467\n","\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9934 - loss: 0.0294\n","LSTM Accuracy: 0.9888888597488403\n","\n","=== GRU ===\n","Epoch 1/3\n","\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.8830 - loss: 0.3528 - val_accuracy: 0.9968 - val_loss: 0.0228\n","Epoch 2/3\n","\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9920 - loss: 0.0599 - val_accuracy: 0.9962 - val_loss: 0.0377\n","Epoch 3/3\n","\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9984 - loss: 0.0152 - val_accuracy: 0.9975 - val_loss: 0.0198\n","\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9961 - loss: 0.0290\n","GRU Accuracy: 0.9949495196342468\n","\n","=== Hyperparameter Tuning: Logistic Regression ===\n","Best Parameters: {'C': 10, 'solver': 'liblinear'}\n","Best CV Score: 0.9963383838383839\n"]}],"source":["# =========================\n","# 1. Imports\n","# =========================\n","import pandas as pd\n","import numpy as np\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import accuracy_score, classification_report\n","from sklearn.model_selection import train_test_split, GridSearchCV\n","\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Embedding, LSTM, GRU, Dense, Dropout, Bidirectional\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","\n","# =========================\n","# 2. Load Processed Data\n","# =========================\n","df = pd.read_csv(\"/content/drive/MyDrive/FakeNewsDetection_Project/processed_fake_news.csv\")\n","\n","X = df[\"clean_text\"]\n","y = df[\"label\"]\n","\n","X_train, X_test, y_train, y_test = train_test_split(\n","    X, y, test_size=0.2, random_state=42\n",")\n","\n","# =========================\n","# 3. TF-IDF + Baseline Models\n","# =========================\n","print(\"\\n=== TF-IDF + Logistic Regression ===\")\n","tfidf = TfidfVectorizer(max_features=5000, ngram_range=(1,2))\n","X_train_tfidf = tfidf.fit_transform(X_train)\n","X_test_tfidf = tfidf.transform(X_test)\n","\n","log_reg = LogisticRegression(max_iter=1000)\n","log_reg.fit(X_train_tfidf, y_train)\n","y_pred_lr = log_reg.predict(X_test_tfidf)\n","\n","print(\"Accuracy:\", accuracy_score(y_test, y_pred_lr))\n","print(classification_report(y_test, y_pred_lr))\n","\n","print(\"\\n=== TF-IDF + Random Forest ===\")\n","rf = RandomForestClassifier(n_estimators=200, random_state=42)\n","rf.fit(X_train_tfidf, y_train)\n","y_pred_rf = rf.predict(X_test_tfidf)\n","\n","print(\"Accuracy:\", accuracy_score(y_test, y_pred_rf))\n","print(classification_report(y_test, y_pred_rf))\n","\n","# =========================\n","# 4. Deep Learning Models\n","# =========================\n","# Tokenizer + Padding\n","max_words = 10000\n","max_len = 200\n","\n","tokenizer = Tokenizer(num_words=max_words, oov_token=\"<OOV>\")\n","tokenizer.fit_on_texts(X_train)\n","\n","X_train_seq = tokenizer.texts_to_sequences(X_train)\n","X_test_seq = tokenizer.texts_to_sequences(X_test)\n","\n","X_train_pad = pad_sequences(X_train_seq, maxlen=max_len, padding=\"post\")\n","X_test_pad = pad_sequences(X_test_seq, maxlen=max_len, padding=\"post\")\n","\n","# -------------------------\n","# Model 1: Simple Dense NN\n","# -------------------------\n","print(\"\\n=== Dense Neural Network ===\")\n","dense_model = Sequential([\n","    Embedding(max_words, 128, input_length=max_len),\n","    tf.keras.layers.GlobalAveragePooling1D(),\n","    Dense(64, activation=\"relu\"),\n","    Dropout(0.5),\n","    Dense(1, activation=\"sigmoid\")\n","])\n","\n","dense_model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n","dense_model.fit(X_train_pad, y_train, validation_split=0.2, epochs=3, batch_size=64)\n","dense_loss, dense_acc = dense_model.evaluate(X_test_pad, y_test)\n","print(\"Dense NN Accuracy:\", dense_acc)\n","\n","# -------------------------\n","# Model 2: LSTM\n","# -------------------------\n","print(\"\\n=== LSTM ===\")\n","lstm_model = Sequential([\n","    Embedding(max_words, 128, input_length=max_len),\n","    LSTM(128, return_sequences=False),\n","    Dropout(0.5),\n","    Dense(1, activation=\"sigmoid\")\n","])\n","\n","lstm_model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n","lstm_model.fit(X_train_pad, y_train, validation_split=0.2, epochs=3, batch_size=64)\n","lstm_loss, lstm_acc = lstm_model.evaluate(X_test_pad, y_test)\n","print(\"LSTM Accuracy:\", lstm_acc)\n","\n","# -------------------------\n","# Model 3: GRU\n","# -------------------------\n","print(\"\\n=== GRU ===\")\n","gru_model = Sequential([\n","    Embedding(max_words, 128, input_length=max_len),\n","    GRU(128, return_sequences=False),\n","    Dropout(0.5),\n","    Dense(1, activation=\"sigmoid\")\n","])\n","\n","gru_model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n","gru_model.fit(X_train_pad, y_train, validation_split=0.2, epochs=3, batch_size=64)\n","gru_loss, gru_acc = gru_model.evaluate(X_test_pad, y_test)\n","print(\"GRU Accuracy:\", gru_acc)\n","\n","# =========================\n","# 5. Hyperparameter Tuning (example for LogReg)\n","# =========================\n","print(\"\\n=== Hyperparameter Tuning: Logistic Regression ===\")\n","param_grid = {\n","    'C': [0.1, 1, 10],\n","    'solver': ['liblinear', 'lbfgs']\n","}\n","grid = GridSearchCV(LogisticRegression(max_iter=1000), param_grid, cv=3, scoring=\"accuracy\")\n","grid.fit(X_train_tfidf, y_train)\n","print(\"Best Parameters:\", grid.best_params_)\n","print(\"Best CV Score:\", grid.best_score_)"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":211},"id":"4vahkaY0mVyu","outputId":"abf207e0-d049-4f35-dea1-fc26b07a9061","executionInfo":{"status":"error","timestamp":1756326407936,"user_tz":-300,"elapsed":1,"user":{"displayName":"syeda subhana","userId":"05196957078571653966"}}},"outputs":[{"ename":"NameError","evalue":"name 'y_pred_dense' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-3812427973.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;31m# Dense NN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Dense NN\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_dense\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;31m# LSTM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'y_pred_dense' is not defined"]}],"source":["from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n","\n","def evaluate_model(name, y_true, y_pred, results):\n","    acc = accuracy_score(y_true, y_pred)\n","    prec = precision_score(y_true, y_pred)\n","    rec = recall_score(y_true, y_pred)\n","    f1 = f1_score(y_true, y_pred)\n","\n","    # Confusion matrix values\n","    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n","\n","    results.append({\n","        \"Model\": name,\n","        \"Accuracy\": acc,\n","        \"Precision\": prec,\n","        \"Recall\": rec,\n","        \"F1-Score\": f1,\n","        \"TN\": tn,\n","        \"FP\": fp,\n","        \"FN\": fn,\n","        \"TP\": tp\n","    })\n","    return results\n","\n","\n","# Collect results\n","results = []\n","\n","# Logistic Regression\n","evaluate_model(\"Logistic Regression\", y_test, y_pred_lr, results)\n","\n","# Random Forest\n","evaluate_model(\"Random Forest\", y_test, y_pred_rf, results)\n","\n","# Dense NN\n","evaluate_model(\"Dense NN\", y_test, y_pred_dense, results)\n","\n","# LSTM\n","evaluate_model(\"LSTM\", y_test, y_pred_lstm, results)\n","\n","# GRU\n","evaluate_model(\"GRU\", y_test, y_pred_gru, results)\n","\n","# Convert to DataFrame for comparison\n","results_df = pd.DataFrame(results)\n","print(\"\\n=== Model Comparison with Confusion Matrix Values ===\")\n","print(results_df)\n"]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","# Metrics to plot\n","metrics = [\"Accuracy\", \"Precision\", \"Recall\", \"F1-Score\"]\n","\n","for metric in metrics:\n","    plt.figure(figsize=(8,5))\n","    plt.bar(results_df[\"Model\"], results_df[metric], color=\"skyblue\")\n","    plt.title(f\"{metric} Comparison Across Models\")\n","    plt.ylabel(metric)\n","    plt.ylim(0, 1)  # all metrics are between 0 and 1\n","    plt.xticks(rotation=30, ha=\"right\")\n","    plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n","    plt.show()\n"],"metadata":{"id":"sVsl1SorvSBe","executionInfo":{"status":"aborted","timestamp":1756326407197,"user_tz":-300,"elapsed":8,"user":{"displayName":"syeda subhana","userId":"05196957078571653966"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["cm_values = [\"TN\", \"FP\", \"FN\", \"TP\"]\n","\n","for val in cm_values:\n","    plt.figure(figsize=(8,5))\n","    plt.bar(results_df[\"Model\"], results_df[val], color=\"lightcoral\")\n","    plt.title(f\"{val} Counts Across Models\")\n","    plt.ylabel(\"Count\")\n","    plt.xticks(rotation=30, ha=\"right\")\n","    plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n","    plt.show()\n"],"metadata":{"id":"sX_WJsnQvTxH","executionInfo":{"status":"aborted","timestamp":1756326407218,"user_tz":-300,"elapsed":2,"user":{"displayName":"syeda subhana","userId":"05196957078571653966"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import confusion_matrix\n","import numpy as np\n","\n","def plot_conf_matrix(y_true, y_pred, model_name, normalize=False):\n","    cm = confusion_matrix(y_true, y_pred)\n","\n","    if normalize:\n","        cm = cm.astype(\"float\") / cm.sum(axis=1)[:, np.newaxis]\n","        fmt = \".2f\"   # show percentages\n","        title = f\"Confusion Matrix (Normalized) - {model_name}\"\n","    else:\n","        fmt = \"d\"    # show counts\n","        title = f\"Confusion Matrix - {model_name}\"\n","\n","    plt.figure(figsize=(4,4))\n","    plt.imshow(cm, interpolation=\"nearest\", cmap=plt.cm.Blues)\n","    plt.title(title)\n","    plt.colorbar()\n","\n","    tick_marks = [0,1]\n","    plt.xticks(tick_marks, [\"Fake\", \"Real\"])\n","    plt.yticks(tick_marks, [\"Fake\", \"Real\"])\n","\n","    # Add numbers inside cells\n","    thresh = cm.max() / 2.\n","    for i in range(cm.shape[0]):\n","        for j in range(cm.shape[1]):\n","            plt.text(j, i, format(cm[i, j], fmt),\n","                     ha=\"center\", va=\"center\",\n","                     color=\"white\" if cm[i, j] > thresh else \"black\")\n","\n","    plt.ylabel(\"True label\")\n","    plt.xlabel(\"Predicted label\")\n","    plt.tight_layout()\n","    plt.show()\n","    plt.close()\n"],"metadata":{"id":"VmmJ_7VotLgA","executionInfo":{"status":"aborted","timestamp":1756326407264,"user_tz":-300,"elapsed":3,"user":{"displayName":"syeda subhana","userId":"05196957078571653966"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plot_conf_matrix(y_test, y_pred_lr, \"Logistic Regression\")"],"metadata":{"id":"keM0wtgztQ74","executionInfo":{"status":"aborted","timestamp":1756326407310,"user_tz":-300,"elapsed":5,"user":{"displayName":"syeda subhana","userId":"05196957078571653966"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plot_conf_matrix(y_test, y_pred_lr, \"Logistic Regression\", normalize=True)"],"metadata":{"id":"3O2vP3ettUh0","executionInfo":{"status":"aborted","timestamp":1756326407345,"user_tz":-300,"elapsed":14,"user":{"displayName":"syeda subhana","userId":"05196957078571653966"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9v1nYVqCmWMO","executionInfo":{"status":"aborted","timestamp":1756326407363,"user_tz":-300,"elapsed":3,"user":{"displayName":"syeda subhana","userId":"05196957078571653966"}}},"outputs":[],"source":["import gradio as gr\n","\n","# Choose the best model (example: LSTM)\n","best_model = lstm_model\n","\n","# Prediction function\n","def predict_news(text):\n","    # Clean text\n","    cleaned = clean_text(text)\n","    seq = tokenizer.texts_to_sequences([cleaned])\n","    pad = pad_sequences(seq, maxlen=max_len, padding=\"post\")\n","    pred = best_model.predict(pad)[0][0]\n","    label = \"Real\" if pred >= 0.5 else \"Fake\"\n","    return { \"Fake\": float(1-pred), \"Real\": float(pred) }\n","\n","# Gradio interface\n","iface = gr.Interface(\n","    fn=predict_news,\n","    inputs=gr.Textbox(lines=4, placeholder=\"Paste a news article here...\"),\n","    outputs=gr.Label(num_top_classes=2),\n","    title=\"Fake News Detector\",\n","    description=\"Enter a news article and see if it's predicted as Real or Fake.\"\n",")\n","\n","iface.launch(share=True)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Y5Z5M8bImb1o","executionInfo":{"status":"aborted","timestamp":1756326407388,"user_tz":-300,"elapsed":2,"user":{"displayName":"syeda subhana","userId":"05196957078571653966"}}},"outputs":[],"source":["import pickle\n","\n","# Save tokenizer\n","with open(\"/content/drive/MyDrive/FakeNewsDetection_Project/tokenizer.pkl\", \"wb\") as f:\n","    pickle.dump(tokenizer, f)\n","\n","# Save model\n","best_model.save(\"/content/drive/MyDrive/FakeNewsDetection_Project/best_model.h5\")\n"]}],"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}